---
Date: {05/28/2023}
Deciders: {Full team}
---

# Structure and Use of OpenAI GPT 3.5 API

## Context and Problem Statement

We want to avoid our app being a reskinned magic 8 ball (i.e. random responses displayed on screen at the press of a button or other event). To do this, we want to take user input and turn that into a unique and applicable response. To this end, we will be using the OpenAI GPT 3.5 API to generate responses from user input, with our current implementation (random responses picked from a list) as a fallback when the API fails.

## Decision Drivers

* Desire an x-factor to bring users back to the site in a day, a week, and a month
* Desire to create user-unique responses and applicable advice
* Desire to avoid 8-ball functionality

### Consequences

* Good, because the fortunes will be more entertaining for users
* Good, because the fortunes will be more applicable to users
* Good, because a specific interaction will not be repeated (i.e. possible fortunes ~ infinity)
* Bad, because API calls create overhead and latency
    * Address: There is already a "thinking" animation baked into our Zoltar. By extending this animation with more intricacies (flickering eyes, words, etc) we can mask the API latency and make the experience seamless for the user. This extended interaction time also creates a more intimate experience for the user.
* Bad, because APIs have downtime
    * Address: If the API call fails or times out, the "normal pathway" (i.e. grabbing a response from responses.json) is followed. This means that adding the GPT API to our website creates no negative effects for users who are not able to use it. 
* Bad, because AI is potentially susceptible to prompt injection
    * Address: We can implement basic defenses. However, zoltar.live runs client-side, so the only negative effect from prompt injection would be felt by the user performing it. This is fundamentally very similar to a user using inspect element to change text (i.e. purposefully going out of their way to break the site). We decided this risk (negative pr?) does not outweight the benefits to our site.

## More Information

We will access the GPT API through serverless functions on Netlify (which in turns uses AWS Lambda functions). This allows us to perform calls without exposing our API key. We then use the Fetch API to interact with the function, passing the user's input and getting a response back from OpenAI.
